{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "classifier_pytorch.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ldselvera/Bi-LSTM-question-classifier/blob/master/classifier_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WYBaJ498oQZ"
      },
      "source": [
        "# standard imports\n",
        "import time\n",
        "import random\n",
        "import os\n",
        "from IPython.display import display\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# pytorch imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data\n",
        "\n",
        "# imports for preprocessing the questions\n",
        "import tensorflow.keras\n",
        "from  tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from  tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# cross validation and metrics\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# progress bars\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJb9gvfa8oQa",
        "outputId": "5ee8bee5-90c6-4043-eb72-393a771431fb"
      },
      "source": [
        "train_df = pd.read_csv(\"Data/train.csv\")\n",
        "test_df = pd.read_csv(\"Data/test.csv\")\n",
        "print('Train data dimension: ', train_df.shape)\n",
        "display(train_df.head())\n",
        "print('Test data dimension: ', test_df.shape)\n",
        "display(test_df.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train data dimension:  (1306122, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>question_text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00002165364db923c7e6</td>\n",
              "      <td>How did Quebec nationalists see their province...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000032939017120e6e44</td>\n",
              "      <td>Do you have an adopted dog, how would you enco...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0000412ca6e4628ce2cf</td>\n",
              "      <td>Why does velocity affect time? Does velocity a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000042bf85aa498cd78e</td>\n",
              "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0000455dfa3e01eae3af</td>\n",
              "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    qid                                      question_text  \\\n",
              "0  00002165364db923c7e6  How did Quebec nationalists see their province...   \n",
              "1  000032939017120e6e44  Do you have an adopted dog, how would you enco...   \n",
              "2  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...   \n",
              "3  000042bf85aa498cd78e  How did Otto von Guericke used the Magdeburg h...   \n",
              "4  0000455dfa3e01eae3af  Can I convert montra helicon D to a mountain b...   \n",
              "\n",
              "   target  \n",
              "0       0  \n",
              "1       0  \n",
              "2       0  \n",
              "3       0  \n",
              "4       0  "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Test data dimension:  (375806, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>question_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000163e3ea7c7a74cd7</td>\n",
              "      <td>Why do so many women become so rude and arroga...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00002bd4fb5d505b9161</td>\n",
              "      <td>When should I apply for RV college of engineer...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00007756b4a147d2b0b3</td>\n",
              "      <td>What is it really like to be a nurse practitio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000086e4b7e1c7146103</td>\n",
              "      <td>Who are entrepreneurs?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0000c4c3fbe8785a3090</td>\n",
              "      <td>Is education really making good people nowadays?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    qid                                      question_text\n",
              "0  0000163e3ea7c7a74cd7  Why do so many women become so rude and arroga...\n",
              "1  00002bd4fb5d505b9161  When should I apply for RV college of engineer...\n",
              "2  00007756b4a147d2b0b3  What is it really like to be a nurse practitio...\n",
              "3  000086e4b7e1c7146103                             Who are entrepreneurs?\n",
              "4  0000c4c3fbe8785a3090   Is education really making good people nowadays?"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MafYJOGx8oQc"
      },
      "source": [
        "def seed_everything(seed=1234):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "seed_everything()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RbkPANV8oQd"
      },
      "source": [
        "def threshold_search(y_true, y_proba):\n",
        "    best_threshold = 0\n",
        "    best_score = 0\n",
        "    for threshold in tqdm([i * 0.01 for i in range(100)]):\n",
        "        score = f1_score(y_true=y_true, y_pred=y_proba > threshold)\n",
        "        if score > best_score:\n",
        "            best_threshold = threshold\n",
        "            best_score = score\n",
        "    search_result = {'threshold': best_threshold, 'f1': best_score}\n",
        "    return search_result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhYSCXcG8oQe"
      },
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwmkKoDU8oQe"
      },
      "source": [
        "embed_size = 300 # how big is each word vector\n",
        "max_features = 95000 # how many unique words to use (i.e num rows in embedding vector)\n",
        "maxlen = 70 # max number of words in a question to use"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wspLgiGw8oQf"
      },
      "source": [
        "puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£', \n",
        " '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n",
        " '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n",
        " '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n",
        " '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]\n",
        "def clean_text(x):\n",
        "    x = str(x)\n",
        "    y=1\n",
        "    for punct in puncts:\n",
        "        x = x.replace(punct, f' {punct} ')\n",
        "    return x\n",
        "\n",
        "train_df[\"question_text\"] = train_df[\"question_text\"].str.lower()\n",
        "test_df[\"question_text\"] = test_df[\"question_text\"].str.lower()\n",
        "\n",
        "train_df[\"question_text\"] = train_df[\"question_text\"].apply(lambda x: clean_text(x))\n",
        "test_df[\"question_text\"] = test_df[\"question_text\"].apply(lambda x: clean_text(x))\n",
        "\n",
        "# fill up the missing values\n",
        "x_train = train_df[\"question_text\"].fillna(\"_##_\").values\n",
        "x_test = test_df[\"question_text\"].fillna(\"_##_\").values\n",
        "\n",
        "# Tokenize the sentences\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(list(x_train))\n",
        "x_train = tokenizer.texts_to_sequences(x_train)\n",
        "x_test = tokenizer.texts_to_sequences(x_test)\n",
        "\n",
        "# Pad the sentences \n",
        "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = pad_sequences(x_test, maxlen=maxlen)\n",
        "\n",
        "# Get the target values\n",
        "y_train = train_df['target'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-x7kTvG88oQg"
      },
      "source": [
        "def load_glove(word_index):\n",
        "    EMBEDDING_FILE = 'Data/embeddings/glove.840B.300d/glove.840B.300d.txt'\n",
        "    def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')[:300]\n",
        "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE, encoding=\"utf8\"))\n",
        "    \n",
        "    all_embs = np.stack(embeddings_index.values())\n",
        "    emb_mean,emb_std = -0.005838499,0.48782197\n",
        "    embed_size = all_embs.shape[1]\n",
        "\n",
        "    # word_index = tokenizer.word_index\n",
        "    nb_words = min(max_features, len(word_index))\n",
        "    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
        "    for word, i in word_index.items():\n",
        "        if i >= max_features: continue\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
        "            \n",
        "    return embedding_matrix "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bDH3O9i8oQg",
        "outputId": "84c1bb99-a144-4a5b-977e-f03ed8d974b1"
      },
      "source": [
        "# missing entries in the embedding are set using np.random.normal so we have to seed here too\n",
        "seed_everything()\n",
        "\n",
        "glove_embeddings = load_glove(tokenizer.word_index)\n",
        "\n",
        "embedding_matrix = np.mean([glove_embeddings], axis=0)\n",
        "np.shape(embedding_matrix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3418: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(95000, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLjcCyZv8oQh"
      },
      "source": [
        "splits = list(StratifiedKFold(n_splits=5, shuffle=True, random_state=10).split(x_train, y_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTNIkFZY8oQh"
      },
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, feature_dim, step_dim, bias=True, **kwargs):\n",
        "        super(Attention, self).__init__(**kwargs)\n",
        "        \n",
        "        self.supports_masking = True\n",
        "\n",
        "        self.bias = bias\n",
        "        self.feature_dim = feature_dim\n",
        "        self.step_dim = step_dim\n",
        "        self.features_dim = 0\n",
        "        \n",
        "        weight = torch.zeros(feature_dim, 1)\n",
        "        nn.init.xavier_uniform_(weight)\n",
        "        self.weight = nn.Parameter(weight)\n",
        "        \n",
        "        if bias:\n",
        "            self.b = nn.Parameter(torch.zeros(step_dim))\n",
        "        \n",
        "    def forward(self, x, mask=None):\n",
        "        feature_dim = self.feature_dim\n",
        "        step_dim = self.step_dim\n",
        "\n",
        "        eij = torch.mm(\n",
        "            x.contiguous().view(-1, feature_dim), \n",
        "            self.weight\n",
        "        ).view(-1, step_dim)\n",
        "        \n",
        "        if self.bias:\n",
        "            eij = eij + self.b\n",
        "            \n",
        "        eij = torch.tanh(eij)\n",
        "        a = torch.exp(eij)\n",
        "        \n",
        "        if mask is not None:\n",
        "            a = a * mask\n",
        "\n",
        "        a = a / torch.sum(a, 1, keepdim=True) + 1e-10\n",
        "\n",
        "        weighted_input = x * torch.unsqueeze(a, -1)\n",
        "        return torch.sum(weighted_input, 1)\n",
        "    \n",
        "class SpatialDropout(nn.Dropout2d):\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(2)    # (N, T, 1, K)\n",
        "        x = x.permute(0, 3, 2, 1)  # (N, K, 1, T)\n",
        "        x = super(SpatialDropout, self).forward(x)  # (N, K, 1, T), some features are masked\n",
        "        x = x.permute(0, 3, 2, 1)  # (N, T, 1, K)\n",
        "        x = x.squeeze(2)  # (N, T, K)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cv8X850d8oQi"
      },
      "source": [
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        \n",
        "        hidden_size = 40\n",
        "        \n",
        "        self.embedding = nn.Embedding(max_features, embed_size)\n",
        "        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n",
        "        self.embedding.weight.requires_grad = False\n",
        "        \n",
        "        self.embedding_dropout = SpatialDropout(0.1)\n",
        "        self.lstm = nn.LSTM(embed_size, hidden_size, bidirectional=True, batch_first=True)\n",
        "        self.gru = nn.GRU(hidden_size * 2, hidden_size, bidirectional=True, batch_first=True)\n",
        "        \n",
        "        self.lstm_attention = Attention(hidden_size * 2, maxlen)\n",
        "        self.gru_attention = Attention(hidden_size * 2, maxlen)\n",
        "        \n",
        "        self.linear = nn.Linear(320, 16)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.out = nn.Linear(16, 1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        h_embedding = self.embedding(x)\n",
        "        h_embedding = self.embedding_dropout(h_embedding)\n",
        "        \n",
        "        h_lstm, _ = self.lstm(h_embedding)\n",
        "        h_gru, _ = self.gru(h_lstm)\n",
        "        \n",
        "        h_lstm_atten = self.lstm_attention(h_lstm)\n",
        "        h_gru_atten = self.gru_attention(h_gru)\n",
        "        \n",
        "        # global average pooling\n",
        "        avg_pool = torch.mean(h_gru, 1)\n",
        "        # global max pooling\n",
        "        max_pool, _ = torch.max(h_gru, 1)\n",
        "        \n",
        "        conc = torch.cat((h_lstm_atten, h_gru_atten, avg_pool, max_pool), 1)\n",
        "        conc = self.relu(self.linear(conc))\n",
        "        conc = self.dropout(conc)\n",
        "        out = self.out(conc)\n",
        "        \n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buzl9CXx8oQj"
      },
      "source": [
        "batch_size = 512 # how many samples to process at once\n",
        "n_epochs = 6 # how many times to iterate over all samples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_IndKjV8oQj",
        "outputId": "c2f9f894-7727-41ce-d166-7b82c6bbe66b"
      },
      "source": [
        "# matrix for the out-of-fold predictions\n",
        "train_preds = np.zeros((len(train_df)))\n",
        "# matrix for the predictions on the test set\n",
        "test_preds = np.zeros((len(test_df)))\n",
        "\n",
        "# always call this before training for deterministic results\n",
        "seed_everything()\n",
        "\n",
        "x_test_cuda = torch.tensor(x_test, dtype=torch.long).cuda()\n",
        "test = torch.utils.data.TensorDataset(x_test_cuda)\n",
        "test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "for i, (train_idx, valid_idx) in enumerate(splits):    \n",
        "    # split data in train / validation according to the KFold indeces\n",
        "    # also, convert them to a torch tensor and store them on the GPU (done with .cuda())\n",
        "    x_train_fold = torch.tensor(x_train[train_idx], dtype=torch.long).cuda()\n",
        "    y_train_fold = torch.tensor(y_train[train_idx, np.newaxis], dtype=torch.float32).cuda()\n",
        "    x_val_fold = torch.tensor(x_train[valid_idx], dtype=torch.long).cuda()\n",
        "    y_val_fold = torch.tensor(y_train[valid_idx, np.newaxis], dtype=torch.float32).cuda()\n",
        "    \n",
        "    model = NeuralNet()\n",
        "    # make sure everything in the model is running on the GPU\n",
        "    model.cuda()\n",
        "\n",
        "    # define binary cross entropy loss\n",
        "    # note that the model returns logit to take advantage of the log-sum-exp trick \n",
        "    # for numerical stability in the loss\n",
        "    loss_fn = torch.nn.BCEWithLogitsLoss(reduction='mean')\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "    train = torch.utils.data.TensorDataset(x_train_fold, y_train_fold)\n",
        "    valid = torch.utils.data.TensorDataset(x_val_fold, y_val_fold)\n",
        "    \n",
        "    train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
        "    valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=False)\n",
        "    \n",
        "    print(f'Fold {i + 1}')\n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        # set train mode of the model. This enables operations which are only applied during training like dropout\n",
        "        start_time = time.time()\n",
        "        model.train()\n",
        "        avg_loss = 0.  \n",
        "        for x_batch, y_batch in tqdm(train_loader, disable=True):\n",
        "            # Forward pass: compute predicted y by passing x to the model.\n",
        "            y_pred = model(x_batch)\n",
        "\n",
        "            # Compute and print loss.\n",
        "            loss = loss_fn(y_pred, y_batch)\n",
        "\n",
        "            # Before the backward pass, use the optimizer object to zero all of the\n",
        "            # gradients for the Tensors it will update (which are the learnable weights\n",
        "            # of the model)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Backward pass: compute gradient of the loss with respect to model parameters\n",
        "            loss.backward()\n",
        "\n",
        "            # Calling the step function on an Optimizer makes an update to its parameters\n",
        "            optimizer.step()\n",
        "            avg_loss += loss.item() / len(train_loader)\n",
        "            \n",
        "        # set evaluation mode of the model. This disabled operations which are only applied during training like dropout\n",
        "        model.eval()\n",
        "        \n",
        "        # predict all the samples in y_val_fold batch per batch\n",
        "        valid_preds_fold = np.zeros((x_val_fold.size(0)))\n",
        "        test_preds_fold = np.zeros((len(test_df)))\n",
        "        \n",
        "        avg_val_loss = 0.\n",
        "        for i, (x_batch, y_batch) in enumerate(valid_loader):\n",
        "            y_pred = model(x_batch).detach()\n",
        "            \n",
        "            avg_val_loss += loss_fn(y_pred, y_batch).item() / len(valid_loader)\n",
        "            valid_preds_fold[i * batch_size:(i+1) * batch_size] = sigmoid(y_pred.cpu().numpy())[:, 0]\n",
        "        \n",
        "        elapsed_time = time.time() - start_time \n",
        "        print('Epoch {}/{} \\t loss={:.4f} \\t val_loss={:.4f} \\t time={:.2f}s'.format(\n",
        "            epoch + 1, n_epochs, avg_loss, avg_val_loss, elapsed_time))\n",
        "        \n",
        "    # predict all samples in the test set batch per batch\n",
        "    for i, (x_batch,) in enumerate(test_loader):\n",
        "        y_pred = model(x_batch).detach()\n",
        "\n",
        "        test_preds_fold[i * batch_size:(i+1) * batch_size] = sigmoid(y_pred.cpu().numpy())[:, 0]\n",
        "\n",
        "    train_preds[valid_idx] = valid_preds_fold\n",
        "    test_preds += test_preds_fold / len(splits)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold 1\n",
            "Epoch 1/6 \t loss=0.1220 \t val_loss=0.1055 \t time=58.23s\n",
            "Epoch 2/6 \t loss=0.1047 \t val_loss=0.1012 \t time=58.14s\n",
            "Epoch 3/6 \t loss=0.0998 \t val_loss=0.0991 \t time=58.23s\n",
            "Epoch 4/6 \t loss=0.0960 \t val_loss=0.0995 \t time=59.62s\n",
            "Epoch 5/6 \t loss=0.0929 \t val_loss=0.0993 \t time=58.21s\n",
            "Epoch 6/6 \t loss=0.0903 \t val_loss=0.0979 \t time=58.08s\n",
            "Fold 2\n",
            "Epoch 1/6 \t loss=0.1239 \t val_loss=0.1064 \t time=58.16s\n",
            "Epoch 2/6 \t loss=0.1060 \t val_loss=0.1021 \t time=58.12s\n",
            "Epoch 3/6 \t loss=0.1007 \t val_loss=0.1009 \t time=57.78s\n",
            "Epoch 4/6 \t loss=0.0971 \t val_loss=0.0994 \t time=57.87s\n",
            "Epoch 5/6 \t loss=0.0940 \t val_loss=0.1002 \t time=57.69s\n",
            "Epoch 6/6 \t loss=0.0912 \t val_loss=0.0988 \t time=57.65s\n",
            "Fold 3\n",
            "Epoch 1/6 \t loss=0.1244 \t val_loss=0.1075 \t time=57.66s\n",
            "Epoch 2/6 \t loss=0.1053 \t val_loss=0.1011 \t time=57.67s\n",
            "Epoch 3/6 \t loss=0.1001 \t val_loss=0.0989 \t time=58.50s\n",
            "Epoch 4/6 \t loss=0.0965 \t val_loss=0.0976 \t time=58.78s\n",
            "Epoch 5/6 \t loss=0.0936 \t val_loss=0.0972 \t time=58.60s\n",
            "Epoch 6/6 \t loss=0.0906 \t val_loss=0.0977 \t time=58.42s\n",
            "Fold 4\n",
            "Epoch 1/6 \t loss=0.1247 \t val_loss=0.1056 \t time=58.88s\n",
            "Epoch 2/6 \t loss=0.1055 \t val_loss=0.1008 \t time=59.15s\n",
            "Epoch 3/6 \t loss=0.1004 \t val_loss=0.0983 \t time=58.66s\n",
            "Epoch 4/6 \t loss=0.0969 \t val_loss=0.0976 \t time=58.79s\n",
            "Epoch 5/6 \t loss=0.0938 \t val_loss=0.0985 \t time=60.10s\n",
            "Epoch 6/6 \t loss=0.0911 \t val_loss=0.0976 \t time=59.07s\n",
            "Fold 5\n",
            "Epoch 1/6 \t loss=0.1228 \t val_loss=0.1086 \t time=57.64s\n",
            "Epoch 2/6 \t loss=0.1051 \t val_loss=0.1040 \t time=57.76s\n",
            "Epoch 3/6 \t loss=0.1000 \t val_loss=0.1001 \t time=57.82s\n",
            "Epoch 4/6 \t loss=0.0961 \t val_loss=0.0995 \t time=57.69s\n",
            "Epoch 5/6 \t loss=0.0931 \t val_loss=0.0984 \t time=59.01s\n",
            "Epoch 6/6 \t loss=0.0904 \t val_loss=0.0986 \t time=58.39s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBY5naw78oQk",
        "outputId": "5fdbcc87-4481-4aea-91c7-6de3f9cc6cff"
      },
      "source": [
        "# Specify a path\n",
        "PATH = \"entire_model.pt\"\n",
        "\n",
        "# Save\n",
        "torch.save(model, PATH)\n",
        "\n",
        "# Load\n",
        "model = torch.load(PATH)\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NeuralNet(\n",
              "  (embedding): Embedding(95000, 300)\n",
              "  (embedding_dropout): SpatialDropout(p=0.1, inplace=False)\n",
              "  (lstm): LSTM(300, 40, batch_first=True, bidirectional=True)\n",
              "  (gru): GRU(80, 40, batch_first=True, bidirectional=True)\n",
              "  (lstm_attention): Attention()\n",
              "  (gru_attention): Attention()\n",
              "  (linear): Linear(in_features=320, out_features=16, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (out): Linear(in_features=16, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lu_4NUrc8oQk",
        "outputId": "62d842db-b90c-4115-a987-824b86b70380"
      },
      "source": [
        "search_result = threshold_search(y_train, train_preds)\n",
        "search_result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:30<00:00,  3.31it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'threshold': 0.36, 'f1': 0.6833205977489615}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKXkB4m38oQk"
      },
      "source": [
        "submission = test_df[['qid']].copy()\n",
        "submission['prediction'] = test_preds > search_result['threshold']\n",
        "submission.to_csv('submission1.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hH5w8uD8oQl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}